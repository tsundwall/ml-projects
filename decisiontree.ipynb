{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35d1d84-d1fa-44a9-9e7f-e27474ec28bf",
   "metadata": {},
   "source": [
    "<font size=\"7\">Tanner Sundwall- Decision Trees CS472</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3382e4a1-0c12-42a2-804e-ec91e60218d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "import graphviz\n",
    "from sklearn import metrics\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce909bfb-b526-4552-a997-1ce5ed66327e",
   "metadata": {},
   "source": [
    "<font size=\"5\">ID3 Algorithm, Cross Validation Algorithm, etc.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "749093a8-3ec1-49e7-87b0-7ecb6e401c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "\n",
    "    def __init__(self, label, nodeType, feature):\n",
    "\n",
    "        self.root = self\n",
    "        self.children = []\n",
    "        self.label = label\n",
    "        self.type = nodeType\n",
    "        self.feature = feature #which feature is this label associated with?\n",
    "\n",
    "\n",
    "    def peek_children(self,mute=False):\n",
    "\n",
    "        list = []\n",
    "        if not mute:\n",
    "            print(\"splits on:\" + self.children[0].feature)\n",
    "        for child in self.children:\n",
    "            list.append(child.label)\n",
    "\n",
    "        return list\n",
    "\n",
    "\n",
    "class DTClassifier():\n",
    "\n",
    "    def get_entropy(self, x): #ret float\n",
    "\n",
    "        tot = 0\n",
    "\n",
    "        for featureValue in list(set(x)):\n",
    "\n",
    "            n_v = x.count(featureValue) / len(x)\n",
    "\n",
    "            sub = -n_v * np.log2(n_v)\n",
    "            tot += sub\n",
    "\n",
    "        return tot\n",
    "\n",
    "    def select_feature(self, df, remainingFeatures, outcomeLabel, mute=False): #x is df-like structure\n",
    "\n",
    "        maxInfoGainFeature = \"\"\n",
    "        maxInfoGain = 0\n",
    "        E_c = self.get_entropy(list(df[outcomeLabel]))\n",
    "\n",
    "        for feature in list(df.columns):\n",
    "            if feature == outcomeLabel:\n",
    "                continue\n",
    "            elif feature not in remainingFeatures:\n",
    "                continue\n",
    "            tot = 0\n",
    "\n",
    "            for featureValue in list(set(df[feature])):\n",
    "\n",
    "                subDf = df[df[feature]==featureValue]\n",
    "                E_f = self.get_entropy(list(subDf[outcomeLabel]))\n",
    "                E_f = (len(subDf)/len(df)) * E_f\n",
    "                tot += E_f\n",
    "\n",
    "            if (E_c - tot) > maxInfoGain:\n",
    "                maxInfoGain = E_c - tot\n",
    "                maxInfoGainFeature = feature\n",
    "\n",
    "        if maxInfoGain == 0: #trivial in this case\n",
    "            return remainingFeatures[0]\n",
    "\n",
    "        if not mute:\n",
    "            print(maxInfoGain)\n",
    "\n",
    "        return maxInfoGainFeature\n",
    "\n",
    "    def get_majority_outcome(self, df, outcomeLabel):\n",
    "\n",
    "        maxCount = 0\n",
    "        maxCountOutcome = \"\"\n",
    "\n",
    "        for outcomeValue in list(set(df[self.outcomeLabel])):\n",
    "\n",
    "            currCount = list(df[self.outcomeLabel]).count(outcomeValue)\n",
    "\n",
    "            if currCount > maxCount:\n",
    "                maxCount = currCount\n",
    "                maxCountOutcome = outcomeValue\n",
    "\n",
    "        return maxCountOutcome\n",
    "\n",
    "    def create_tree(self, df, remainingFeatures, rootName, currFeature, outcomeLabel, mute):\n",
    "\n",
    "        rootNode = TreeNode(rootName, \"label\", currFeature)\n",
    "\n",
    "        if len(list(set(df[outcomeLabel]))) == 1:\n",
    "            child = TreeNode(list(set(df[outcomeLabel]))[0], \"resolution\", \"resolution\")\n",
    "            child.root = rootNode\n",
    "            rootNode.children.append(child)\n",
    "\n",
    "            return rootNode\n",
    "\n",
    "        elif len(remainingFeatures) == 1:\n",
    "\n",
    "            child = TreeNode(self.get_majority_outcome(df, outcomeLabel), \"resolution\", \"resolution\")\n",
    "            child.root = rootNode\n",
    "            rootNode.children.append(child)\n",
    "\n",
    "            return rootNode\n",
    "\n",
    "        else:\n",
    "            F_hat = self.select_feature(df, copy.deepcopy(remainingFeatures), outcomeLabel, mute)\n",
    "\n",
    "            remainingFeatures.remove(F_hat)\n",
    "            for featureValue in list(set(df[F_hat])):\n",
    "                childBranch = self.create_tree(df[df[F_hat]==featureValue], copy.deepcopy(remainingFeatures), rootName=featureValue, currFeature = F_hat, outcomeLabel=outcomeLabel, mute=mute)\n",
    "                childBranch.root = rootNode\n",
    "                rootNode.children.append(childBranch)\n",
    "\n",
    "            return rootNode\n",
    "\n",
    "    def predict(self, df, treeRoot, outcomeLabel):\n",
    "\n",
    "        resolutions = []\n",
    "        allOutcomes = list(df[outcomeLabel])\n",
    "\n",
    "        for obs in df.itertuples():\n",
    "\n",
    "            noResolution = True\n",
    "            currNode = treeRoot\n",
    "            currFeature = treeRoot.children[0].feature\n",
    "\n",
    "            while noResolution:\n",
    "\n",
    "                value = getattr(obs,currFeature)\n",
    "                childrenList = currNode.peek_children(mute=True)\n",
    "\n",
    "                try:\n",
    "                    branchIndex = childrenList.index(value)\n",
    "\n",
    "                except:\n",
    "                    defaultValue = max(set(allOutcomes), key=allOutcomes.count)\n",
    "                    resolutions.append(defaultValue)\n",
    "                    break\n",
    "\n",
    "                currNode = currNode.children[branchIndex]\n",
    "\n",
    "                if currNode.children[0].feature == \"resolution\":\n",
    "                    resolutions.append(currNode.children[0].label)\n",
    "                    noResolution = False\n",
    "\n",
    "                else:\n",
    "                    currFeature = currNode.children[0].feature\n",
    "\n",
    "        return resolutions\n",
    "\n",
    "    def score(self, vals, preds):\n",
    "\n",
    "        compareDf = pd.DataFrame([vals, preds]).transpose()\n",
    "        compareDf['result'] = compareDf[0] == compareDf[1]\n",
    "\n",
    "        return np.mean(list(compareDf['result']))\n",
    "\n",
    "def crossValidate(arffString, k, outcomeLabel, convertColNames=False, mute=True):\n",
    "\n",
    "    data = arff.loadarff(arffString)\n",
    "\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    if convertColNames:\n",
    "        convertDashColNames(df)\n",
    "\n",
    "    dtObj = DTClassifier()\n",
    "    df = df.sample(frac=1)\n",
    "    resultsTbl = []\n",
    "    testSetSize = int(len(df) / k)\n",
    "\n",
    "    for testSet in range(1, k+1):\n",
    "\n",
    "        testSetIndexStart = (testSet - 1) * testSetSize\n",
    "        testSetIndexEnd = testSet * testSetSize\n",
    "        testSetDf = df[testSetIndexStart:testSetIndexEnd]\n",
    "        trainingSetDf = pd.concat([df[:testSetIndexStart],df[testSetIndexEnd:]])\n",
    "        tree = dtObj.create_tree(trainingSetDf, copy.deepcopy(list(trainingSetDf.columns)), rootName=\"start\", currFeature = \"na\", outcomeLabel=outcomeLabel, mute=mute)\n",
    "\n",
    "        trainingPreds = dtObj.predict(trainingSetDf, tree, outcomeLabel)\n",
    "        trainingAccuracy = dtObj.score(list(trainingSetDf[outcomeLabel]), trainingPreds)\n",
    "\n",
    "        testPreds = dtObj.predict(testSetDf, tree, outcomeLabel)\n",
    "        testAccuracy = dtObj.score(list(testSetDf[outcomeLabel]), testPreds)\n",
    "\n",
    "        resultsTbl.append([trainingAccuracy,testAccuracy])\n",
    "\n",
    "    return resultsTbl\n",
    "\n",
    "def convertDashColNames(df):\n",
    "\n",
    "    listCols = []\n",
    "    for each in list(df.columns):\n",
    "        listCols.append(each.replace(\"-\", \"_\"))\n",
    "\n",
    "    df.columns = listCols\n",
    "\n",
    "def trainModel(arffString, outcomeLabel, mute):\n",
    "\n",
    "    data = arff.loadarff(arffString)\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    dtObj = DTClassifier()\n",
    "    return dtObj.create_tree(df, copy.deepcopy(list(df.columns)), rootName=\"start\", currFeature=\"na\", outcomeLabel=outcomeLabel, mute=mute)\n",
    "\n",
    "def scoreModel(modelTree, arffString, outcomeLabel):\n",
    "\n",
    "    data = arff.loadarff(arffString)\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    dtObj = DTClassifier()\n",
    "    preds = dtObj.predict(df, modelTree, outcomeLabel)\n",
    "\n",
    "    return dtObj.score(list(df[outcomeLabel]), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3d86c-15cc-4f6e-9fd0-d84a77c31ea2",
   "metadata": {},
   "source": [
    "<font size=\"5\">1.1- Debug (Lenses Dataset)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef3f76da-ca1f-408e-855a-082993bf86e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Gain Splits:\n",
      "\n",
      "0.5487949406953985\n",
      "0.7704260414863778\n",
      "0.4591479170272448\n",
      "0.9182958340544896\n",
      "0.3166890883150208\n",
      "1.0\n",
      "\n",
      "Mean Test Set Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Info Gain Splits:\\n\")\n",
    "modelTree = trainModel(\"lenses.arff\", \"contact_lenses\", False)\n",
    "print(\"\\nMean Test Set Accuracy:\\n\")\n",
    "scoreModel(modelTree, \"lenses_test.arff\", \"contact_lenses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023f46b-f8a9-4994-9f36-d4f4326f321f",
   "metadata": {},
   "source": [
    "<font size=\"5\">1.2- Evaluation (Zoo Dataset)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb95a28c-9af9-45f2-bccb-7e62edbf5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Gain Splits:\n",
      "\n",
      "1.3630469031539394\n",
      "0.6892019851173654\n",
      "0.8631205685666308\n",
      "0.7219280948873623\n",
      "0.7219280948873623\n",
      "0.8256265261578954\n",
      "0.8865408928220899\n",
      "0.6962122601251458\n",
      "0.9852281360342515\n",
      "\n",
      "Mean Test Set Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.147"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Info Gain Splits:\\n\")\n",
    "modelTree = trainModel(\"zoo.arff\", \"type\", False)\n",
    "print(\"\\nMean Test Set Accuracy:\\n\")\n",
    "scoreModel(modelTree, \"zoo_test.arff\", \"type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dba2c-cab8-44f2-b87f-2c79ec57181c",
   "metadata": {},
   "source": [
    "<font size=\"5\">2.2- Cross Validation (Cars Dataset)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a43f8b28-98e9-44ee-b3d7-3a2bceee845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   training      test\n",
      "0       1.0  0.877907\n",
      "1       1.0  0.901163\n",
      "2       1.0  0.883721\n",
      "3       1.0  0.843023\n",
      "4       1.0  0.930233\n",
      "5       1.0  0.901163\n",
      "6       1.0  0.877907\n",
      "7       1.0  0.872093\n",
      "8       1.0  0.906977\n",
      "9       1.0  0.906977\n",
      "\n",
      "mean test accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8901162790697675"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = crossValidate(\"cars.arff\", 10, \"class\")\n",
    "reportDf = pd.DataFrame(report, columns=[\"training\",\"test\"])\n",
    "print(reportDf)\n",
    "print(\"\\nmean test accuracy:\\n\")\n",
    "np.mean(reportDf[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56f81f-d32e-4423-8334-c23c6500d724",
   "metadata": {},
   "source": [
    "<font size=\"5\">2.3- Cross Validation (Voting Dataset)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef67421e-1d1c-46c4-9f00-5a0103991c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   training      test\n",
      "0       1.0  0.953488\n",
      "1       1.0  0.930233\n",
      "2       1.0  0.906977\n",
      "3       1.0  1.000000\n",
      "4       1.0  0.883721\n",
      "5       1.0  0.883721\n",
      "6       1.0  0.930233\n",
      "7       1.0  0.953488\n",
      "8       1.0  0.976744\n",
      "9       1.0  0.953488\n",
      "\n",
      "mean test accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9372093023255814"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = crossValidate(\"voting_with_missing.arff\", 10, \"Class\", convertColNames=True)\n",
    "reportDf = pd.DataFrame(report, columns=[\"training\",\"test\"])\n",
    "print(reportDf)\n",
    "print(\"\\nmean test accuracy:\\n\")\n",
    "np.mean(reportDf[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920ff7b-2f8f-4799-8c79-0130bc9e4eb4",
   "metadata": {},
   "source": [
    "<font size=\"5\">2.4- Discuss Your Results</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c30a8e-86c3-44de-8069-0f3c9d56afab",
   "metadata": {},
   "source": [
    "**Results are non-deterministic due to row shuffling; printed results may vary slightly from report**\n",
    "\n",
    "Both cross-validation results exhibited high accuracy. The mean accuracy across the 10 test folds for “Cars” was 94.88%. No fold did any worse than 90.7%, and no better than 98%. All training sets saw 100% accuracy.\n",
    "\n",
    "For the voting dataset, the training data saw 93.48% accuracy, only slightly lower than for “Cars”. No fold did any worse than 88.37%, and no better than 97.7%. Again, all training sets saw 100% accuracy.\n",
    "\n",
    "We would expect to see lower accuracies if the training set was smaller in proportion to the test set (like in the ‘Lenses’ case). In such cases, sample sizes may not be high enough to best approximate the best attributes to place shallower in the tree.\n",
    "\n",
    "Why were the training sets so accurate? Because the tree was induced from this data, we expect very high accuracy. 100% accuracy occurs when all permutations of data only produce one outcome (that is, observation with all the same attributes have homogeneous results). There are no cases in which all features have been used, and a mixed set of results exist when deciding on the leaf node. In cases where training sets are much larger (or noise is much greater), we would expect less than 100% accuracy when testing the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfe377-1eb5-4b00-815c-460928e5d568",
   "metadata": {},
   "source": [
    "<font size=\"5\">3.1- 'Cars' Decision Tree Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "026a5b3d-76ab-402c-ac17-9cd22bf9544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits on:safety\n",
      "[b'med', b'high', b'low']\n",
      "\n",
      "b'high':\n",
      "splits on:resolution\n",
      "[b'unacc']\n",
      "\n",
      "b'med':\n",
      "splits on:persons\n",
      "[b'4', b'more', b'2']\n",
      "\n",
      "b'low':\n",
      "splits on:persons\n",
      "[b'4', b'more', b'2']\n"
     ]
    }
   ],
   "source": [
    "modelTree = trainModel(\"cars.arff\", \"class\",True)\n",
    "print(modelTree.peek_children())\n",
    "print(\"\\nb'high':\")\n",
    "print(modelTree.children[2].peek_children())\n",
    "print(\"\\nb'med':\")\n",
    "print(modelTree.children[0].peek_children())\n",
    "print(\"\\nb'low':\")\n",
    "print(modelTree.children[1].peek_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a8a4d-5704-4d5d-ba86-701de08e1bbd",
   "metadata": {},
   "source": [
    "The first branch in the “Cars” decision tree was split on the feature “safety”. This means that, across all features in the dataset, ‘safety’ had the highest information gain. This means that its sub-branches had low entropy, meaning that the splits were relatively homogenous compared to other features.\n",
    "\n",
    "If we dig deeper into the “high safety” branch, the “persons” attribute was the next to be split. This means that among the subset of data with high safety, the number of persons gives the maximum information gain for the next split. If we sift down the “mid safety” branch, we get the same split.\n",
    "\n",
    "What’s interesting is that if we traverse the “low safety” branch, we immediately arrive at a homogeneous solution; all cases of low safety lead to class “unacc”. Not a single datapoint with this attribute had class “acc”, and we know that for each cross validation tree that was induced, a similar result will follow (“low safety”->”unacc”). The homogeneity of this branch is likely what propelled “safety” to being the first attribute chosen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f550b10-870e-4dbd-a600-e66f65ae7801",
   "metadata": {},
   "source": [
    "<font size=\"5\">3.2- 'Voting' Decision Tree Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "106a45a1-8052-44a0-b82b-7821d1ebb79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits on:physician-fee-freeze\n",
      "[b'?', b'y', b'n']\n",
      "\n",
      "b'y':\n",
      "splits on:mx-missile\n",
      "[b'?', b'n', b'y']\n",
      "\n",
      "b'n':\n",
      "splits on:synfuels-corporation-cutback\n",
      "[b'?', b'n', b'y']\n",
      "\n",
      "b'?':\n",
      "splits on:adoption-of-the-budget-resolution\n",
      "[b'?', b'y', b'n']\n",
      "\n",
      "b'y',b'y':\n",
      "splits on:resolution\n",
      "[b'republican']\n",
      "\n",
      "b'y',b'n':\n",
      "splits on:resolution\n",
      "[b'democrat']\n",
      "\n",
      "b'y',b'?':\n",
      "splits on:anti-satellite-test-ban\n",
      "[b'?', b'y', b'n']\n"
     ]
    }
   ],
   "source": [
    "modelTree = trainModel(\"voting_with_missing.arff\", \"Class\",True)\n",
    "print(modelTree.peek_children())\n",
    "print(\"\\nb'y':\")\n",
    "print(modelTree.children[0].peek_children())\n",
    "print(\"\\nb'n':\")\n",
    "print(modelTree.children[1].peek_children())\n",
    "print(\"\\nb'?':\")\n",
    "print(modelTree.children[2].peek_children())\n",
    "print(\"\\nb'y',b'y':\")\n",
    "print(modelTree.children[0].children[0].peek_children())\n",
    "print(\"\\nb'y',b'n':\")\n",
    "print(modelTree.children[0].children[1].peek_children())\n",
    "print(\"\\nb'y',b'?':\")\n",
    "print(modelTree.children[0].children[2].peek_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef1820-0bbe-4a09-98e8-86f4f36beafb",
   "metadata": {},
   "source": [
    "In the “Voting” decision tree, the first branch is on “physician_fee_freeze”. As I will note later, unknown attributes were kept as their own intrinsic values. By being split on first, we know that this attribute holds lots of information about the class of the individual (Democrat/Republican). \n",
    "\n",
    "Down the “yes” branch, “synfuels_corporation_cutback” is the next branching attribute. This is a different attribute than the branching attribute for the “no” and “?” branches (“adoption_of_the_budget_resolution” and “mx_missle” respectively). This means that across all three subsets of data, a different attribute contains the most amount of remaining information. \n",
    "\n",
    "If we dig a bit deeper into those who said yes to 'physician-fee-freeze', their response to 'synfuels-corporation-cutback' leads to a variety of next splits. It is quite apparent that the split feature for any given attribute value seems to differ greatly. We also see that a resolution (leaf node) is reached for those who had an unknown response to the 'synfuels-corporation-cutback' question; although this may be a case of overfitting, where only one or a few individuals exist in this leaf node, making it easily homogenous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d861d8a-4906-4ebc-b8d9-3d445c33eb7b",
   "metadata": {},
   "source": [
    "<font size=\"5\">3.3- Handling Unknown Attributes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4da5f-4b68-472e-8e0e-ac73c71ed87b",
   "metadata": {},
   "source": [
    "Given the large number of unknown attributes in the “Voting” dataset, I made the assumption that “?” was its own attribute; that it holds some intrinsic value that can predict class (Democrat/Republican). Essentially, I made the assumption that unknown values are not randomly distributed across outcomes. Without exact knowledge of the data, we can also potentially infer that an unknown response may mean “I do not know”, which may result to more Republicans or Democrats. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb8468c-320b-4042-979e-a49fe67b6dbb",
   "metadata": {},
   "source": [
    "<font size=\"5\">4.1- Voting Dataset- Scikit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c5269-765c-4bd1-b26c-bf0c046b22dc",
   "metadata": {},
   "source": [
    "With the DecisionTreeClassifier() method in scikit-learn, we run into some limitations; inputs must be numerical. This also means that splits can only be binary, and therefore we can’t have a feature with any more than two potential values. In these cases, a feature encoded as (0,1,2) will be treated as ordinal, which isn’t usually a good assumption. Because of this complication, features with more than two attributes must be one-hot encoded, which may lead to a very deep tree. With numerical data, it is also possible to split on a feature more than once, which may not make sense in many cases. \n",
    "\n",
    "In the case of the voting dataset, we only have features with binary classifiers, so we shouldn't run into any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a827bd11-e1a0-4c11-88e9-38112fe79d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9220183486238532"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff(\"voting_with_missing.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "encode = preprocessing.LabelEncoder() #label encoder fine for binary variables; no need to hot encode\n",
    "df = df.apply(encode.fit_transform)\n",
    "\n",
    "y = pd.DataFrame(df['Class'])\n",
    "del df[df.columns[-1]]\n",
    "\n",
    "dfTrain = df[:int(len(df)/2)]\n",
    "yTrain = y[:int(len(df)/2)]\n",
    "dfTest = df[int(len(df)/2):]\n",
    "yTest = y[int(len(df)/2):]\n",
    "\n",
    "cl = DecisionTreeClassifier(max_depth=3)\n",
    "cl = cl.fit(dfTrain,yTrain)\n",
    "\n",
    "preds = cl.predict(dfTest)\n",
    "print(\"Test Accuracy:\")\n",
    "metrics.accuracy_score(preds, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0a94b-660b-4919-86f5-72cc9921b51d",
   "metadata": {},
   "source": [
    "Data was split in half for the training and test data. I wanted to see if a simpler tree could perform similarly to a default configuration, so i set max_depth=4. The default model and the modified model performed very similarly, so I kept the simpler one (both had accuracy ~92%). \n",
    "\n",
    "This test accuracy performs very similarly to the one cross validated on my ID3 algorithm, which saw 93% test accuracy. It would be interesting to see how much better the results would be with this model if I were to implement cross validation methods.\n",
    "\n",
    "Looking at the tree below, it is quite a bit simpler than my model which didn't limit tree depth. This one is much easier to read, and may be more interpretable across domains. Another reason for its simplicity is the strict binary splits implemented. 'physician-fee-freeze' is still the first attribute to split on, but the branch structure deviates from mine greatly after that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d26511d-1549-4af7-b9f1-8b34663ec120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- physician-fee-freeze <= 1.50\n",
      "|   |--- aid-to-nicaraguan-contras <= 0.50\n",
      "|   |   |--- crime <= 1.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- crime >  1.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- aid-to-nicaraguan-contras >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- physician-fee-freeze >  1.50\n",
      "|   |--- duty-free-exports <= 1.50\n",
      "|   |   |--- synfuels-corporation-cutback <= 1.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- synfuels-corporation-cutback >  1.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- duty-free-exports >  1.50\n",
      "|   |   |--- anti-satellite-test-ban <= 1.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- anti-satellite-test-ban >  1.50\n",
      "|   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(cl, feature_names=list(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd9495-c8b2-4cd4-b580-417025f0479d",
   "metadata": {},
   "source": [
    "<font size=\"5\">4.2- Example Dataset- Predicting NFL wins and losses (Scikit)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c714b70c-0b99-472b-99f2-f5ff8bd57757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6895161290322581"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nflDf = pd.read_csv(\"nflEdited.csv\")\n",
    "y = pd.DataFrame(nflDf['Result'])\n",
    "del nflDf[nflDf.columns[-1]]\n",
    "\n",
    "nflDfTrain = nflDf[:500]\n",
    "yTrain = y[:500]\n",
    "nflDfTest = nflDf[500:]\n",
    "yTest = y[500:]\n",
    "\n",
    "cl = DecisionTreeClassifier(max_depth=4,criterion=\"entropy\")\n",
    "cl = cl.fit(nflDfTrain,yTrain)\n",
    "\n",
    "nflPreds = cl.predict(nflDfTest)\n",
    "print(\"Test Accuracy:\")\n",
    "metrics.accuracy_score(nflPreds, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c6467-1be7-472c-88a5-8e20c6ddcb82",
   "metadata": {},
   "source": [
    "I exported data of the last 1000 NFL games from Stathead to complete this analysis. I used half the dataset as training data and half as test data. The goal is to predict whether the home team won or lost the game, given several team/player stats from that game.\n",
    "\n",
    "The NFL dataset saw 65% accuracy with all parameters untouched. Using just entropy, it saw 67% accuracy. To reduce dimensionality and potential overfitting, I tried an iteration where I set the max depth to 3. It yielded an accuracy of 70%, which may be worth reducing dimensionality for, especially if it needs to be interpreted visually. No other parameter tweaks got the accuracy over 70%. The accuracy above reflects a model that uses entropy and has max depth of 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478928cb-32cc-49c7-8a13-14bf290255e2",
   "metadata": {},
   "source": [
    "<font size=\"5\">5- Visualizing NFL Decision Tree</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9435a03f-9361-4fca-b2d4-029bd3042d68",
   "metadata": {},
   "source": [
    "As seen in the tree below, passer rating was the first feature to be split, which follows with general football intuition. When passer rating was below 111.3, number of turnovers forced was then evaluated. At any given level, the children nodes seem to evaulate different features, making it a bit hard to follow. Other common feature splits among the tree include DY/P (defensive yards allowed per play), penalty yards, and total offense allowed. \n",
    "\n",
    "Another reason I wanted to limit the depth of the tree was to see which features were chosen by the algorithm. The ones in the shallow portion and the ones i listed above are all features that I had hypothesized as having predictive value, and surprisingly correlate with talking points/discussion by sports analysts and commentators.\n",
    "\n",
    "At the leaf nodes, the visualization allows us to see the homogeneity among outcomes. One that stands out is the furthest left leaf node; all 154 observations at this branch were Losses. The intution along this branch checks out; low passer rating, low turnovers forced, low offensive yards per attempt, and low opposing penalty yards.\n",
    "\n",
    "While it is a fairly simply tree to glaze over, some of the intution seems to fall apart at lower levels though, especially when a feature is split on a second time. When passer rating is over 111.3, it immediately splits again. Overall, I think given the numerical nature of the data and the poor accuracy (68% seems low), there are likely other algorithms that would be much more effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "756423cd-bb23-4cc4-8343-9a207aa2ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook report.ipynb to html\n",
      "[NbConvertApp] Writing 654646 bytes to report.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --execute --to html report.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
